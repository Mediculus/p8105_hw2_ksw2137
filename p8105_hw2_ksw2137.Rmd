---
title: "P8105 Data Science I - Homework 2"
author: "Kevin S.Wongsodirdjo   UNI: ksw2137"
date: "10/1/2019"
output: github_document
---

```{r setup, include = FALSE, message = FALSE, warning = FALSE}
knitr::opts_chunk$set(echo = TRUE, eval = TRUE, message = FALSE, warning = FALSE)
```



# Introduction
R Markdown document for P8105 homework 2. Code chunk below shows that we are loading the required packages in order to manipulate the imported data/table.

```{r package_load}

# Loads the necessary packages
Packages <- c("tidyverse", "dplyr", "readxl", "knitr")
invisible(lapply(Packages, library, character.only = TRUE))

```



# Problem 1 - Data Import for Mr. Trash Wheel, 2017 Precipitation, & 2018 Precipitation and Data Clean-up
**Update 10/1/2019**: Jeff notified that 2019 Trash-Wheel data exists and that we will be using it instead. 

We are loading datasets from Healthy Harbor Water Wheel's dataset, particularly from the sheets: "Mr. Trash Wheel", "2018 Precipitation", and "2017 Precipitation". While the Mr. Trash Wheel dataset is generally "tidy", we will modify these further to make it easier to work with the data. Dataset for precipitation from 2017 and 2018 were on separate sheets and needed to be merged since we would like a combined dataset. 

```{r trash_precip_dataset}

# Update 10/1/2019: There are new datapoints for Mr. Trash Wheel, so we are using a new datasource. Range
# was modified to include the new datapoints.

# Import excel sheet and piping to clean data for Mr. Trash Wheel
trash_wheel_data <- 
  read_excel("./data/trash_wheel/Trash-Wheel-Collection-Totals-8-6-19.xlsx",
             sheet = "Mr. Trash Wheel",                       # Specifies which sheet to read
             range = "A2:N408") %>%                           # Specifies the cells imported
  janitor::clean_names() %>%                                  # renames column titles as x_y and lowercases
  drop_na(year) %>%                                           # drops any rows containing NA in "year" column
  mutate(
    date = format(date, format = "%d"),                       # Changes the date format from y/m/d to d
    sports_balls = round(sports_balls, 0),                    # Rounds the numbers in sports_balls to integers
    sports_balls = as.integer(sports_balls),                  # Converts type from double to integers
    month = str_to_lower(month)) %>%                          # Makes months to have lowercases
  select(dumpster, year, month, everything())                 # Re-arranges the column to be "tidier"




# Reads the 2017 precipitation data
precip2017_data <- 
  read_excel("./data/trash_wheel/Trash-Wheel-Collection-Totals-8-6-19.xlsx", 
             sheet = "2017 Precipitation",                    # Specifies the sheet
             range = "A2:B14") %>%                            # Specifies range of cells to be read
  janitor::clean_names() %>%                                  # turns column names to lowercases
  mutate(year = "2017") %>%                                   # Adds year column
  select(year, everything())                                  # Re-arrange so year is 1st column
  

# Reads the 2018 precipitation data
# Update 10/1/2019: Since the precipitation 2018 data now contains complete variables, drop_na() was removed
precip2018_data <- 
  read_excel("./data/trash_wheel/Trash-Wheel-Collection-Totals-8-6-19.xlsx", 
             sheet = "2018 Precipitation",                    # Specifies the sheet
             range = "A2:B14") %>%                            # Specifies range of cells to be read
  janitor::clean_names() %>%                                  # turns column names to lowercases
  mutate(year = "2018") %>%                                   # Adds year column
  select(year, everything())                                  # Re-arrange so year is 1st column 


# New dataframe that merged precip2017 and precip2018 by year, then month, then "total". 
merged_precip1718_data <- 
  full_join(precip2017_data, precip2018_data,             # Uses full join using 3 parameters in sequence
            by = c("year", "month", "total")) %>% 
  mutate(month = str_to_lower(month.name[month])) %>%     # changes month from "1" to "january" and so on
  rename(monthly_precip = total)                          # renames the total column to monthly_precip

```

Data from Mr. Trash Wheel was obtained from Healthy Harbor Water Wheel's website. It contains a total of `r ncol(trash_wheel_data)` variables (categories, including dumpster #) containing `r nrow(trash_wheel_data)` observations each. Identifying variables are `dumpster`, `year`, `month`, and `date`. We also have key variables that lists the total amount of variables per dumpster collected at date `x`. Examples are:

* The trash `weight_tons` (in tons)
* Trash `volume_cubic_yards` (in cubic yards) 
* Amount of `cigarette_butts`, `plastic_bottles`, or `polystyrene` per dumpster. 

Interestingly, there were also `sports_balls` included, which has a total median of `r median(pull(trash_wheel_data, sports_balls))` balls per dumpster. 

**UPDATE 10/1/2019**: New datapoints for precipitation was added (sourcefile updated to 2019 version) and the range is now from Jan 2017-Dec 2018. 

The combined precipitation data has a total of `r nrow(merged_precip1718_data)` observations corresponding to each month (Jan 2017-Dec 2018) and its precipitate in inches, which is under the `monthly_precip` column. The `year` identifier was added and merged as it was not included in the original. Total measured precipitation for 2018 was `r sum(pull(precip2018_data, total))` inches, taking into account that the range of 2018 data was from Jan 2018-Jul 2018.



# Problem 2 - S&P 500 Index, Unemployment, and Presidency Polls Data
Making a merged data between polls, unemployment, and S&P 500 Index data obtained from FiveThirtyEight, a website that focuses on graphs. Since structure is slightly different, we have to reorganize the table and use the year & month as the identifier during merging. 

```{r 538data}

# Importing polls data, split the y/m/d date into individual columns. Also changed month from numeric to 
# abbreviated form
pols_month_data <- 
  read_csv("./data/538/pols-month.csv") %>%                              # Reads the file
  janitor::clean_names() %>%                                             # Cleans the column names
  separate(col = mon,                                                    # Separates y/m/d col into its components
           into = c("year", "month", "date"), "-",                       # "-" is the separation point
           convert = TRUE) %>%                                           # converts new columns to numeric
  mutate(
    month = str_to_lower(month.abb[as.numeric(month)]),                  # Change month from "1" to "jan", etc
    prez = prez_gop - prez_dem,                                          # Added column for "presidency" by (x-y)
    prez = factor(prez, labels = c("dem", "gop", "gop"))) %>%            # Change new column to factor and relabeled
  select(year, month, prez, everything(), -date, -prez_gop, -prez_dem)   # Re-arrange columns and remove unwanteds


# Loads S&P 500 data, separate m/d/y into individual columns and change month to abbreviated form.
snp_data <- 
  read_csv("./data/538/snp.csv") %>%                  # Reads the file
  janitor::clean_names() %>%                          # Cleans the column names
  separate(col = date,                                # Separates y/m/d column into its components
           into = c("month", "date", "year"), "/",    # "/" is the point of separation
           convert = TRUE) %>%                        # converts new columns to numeric
  select(year, month, close) %>%                      # Re-arrangement of columns
  arrange(year, month) %>%                            # Turn into ascending order (to match other df)
  mutate(month = str_to_lower(month.abb[month]))      # Change month from "1" to "jan", etc


# Importing unemployment data and then turn it from wide to long format.
unemployment_data <- 
  read_csv("./data/538/unemployment.csv") %>%     # Reads the file
  janitor::clean_names() %>%                      # Cleans the column names
  pivot_longer(
    jan:dec,                                      # Turns into longform by "merging" month columns
    names_to = "month",                           # labels "month" to new column
    values_to = "unemp_rate")                     # labels for column containing values


# Merging the above dataframes by using pols_month_data as the reference.
merged_538_data <-
  left_join(pols_month_data, snp_data, by = c("year", "month")) %>%   # merged snp into pols_month data
  left_join(unemployment_data, by = c("year", "month")) %>%           # merged unemp to the pols+S&P data
  rename(snp_close = close)                                           # renames the close column to specify for S&P

```

The cleaned `pols_month_data` dataset is a `r nrow(pols_month_data)` x `r ncol(pols_month_data)` tibble (row x column). `prez` column was added to show which political party the presidency was under. The data ranges from Jan 1947-Jun 2015. They also contain the number of democratic/GOP governors/senators/representative during the specified dates. 

Cleaned S&P 500 dataset is named `snp_data`. It is `r nrow(snp_data)` x `r ncol(snp_data)` and has variables `year`, `month`, and `close` (index value on market close). Data ranges from Jan 1950-Jul 2015. 

The cleaned `unemployment_data` data is a `r nrow(unemployment_data)` x `r ncol(unemployment_data)` tibble and ranges from Jan 1948-Jun 2015. Since the original dataset doesn't have values from 07/2015-12/2015, the dataframe places `NA` for their values when converting to long form. 

The final `merged_538_data` was formed using `left_join()` by first merging `snp_data` dataset into `pols_month_data`. Then, `unemployment_data` is merged into the resulting dataframe, which is a `r nrow(merged_538_data)` x `r ncol(merged_538_data)` tibble. Key variables from the 3 datasets:

* `year`        : "Identifier"; specifies the year of the event
* `month`       : "Identifier"; specifies the month of the event
* `prez`        : Indicates which party the president leans to
* `snp_close`   : S&P 500 index value at market closing.
* `unemp_rate`  : Percentage of unemployment (unemployment rate)


Since our reference dataset, `pols_month_data`, ranges from Jan 1947-Jun 2015, the `NA` values from `unemployment_data` as well as `snp_data`'s datapoint on Jul 2015 were not included. However, new `NA` values were formed under `unemployment_data` and `snp_data` column since our reference starts from `year` 1947 while `unemployment_data` starts at 1948 and `snp_data` starts at 1950.



# Problem 3 - Baby Names Data Processing
We are using data from NYC Open on baby names' popularity and will create a table that shows "popularity ranking".

## Importing baby data & cleaning up
Upon skimming the original `.csv` dataset, various issues with the syntax of the data were spotted. These issues, while not "critical", needs to be cleaned up so we could work easily with the data. Issues are:

* Inconsistent categorization naming:
  * ASIAN AND PACIFIC ISLANDER vs. ASIAN AND PACI
  * BLACK NON HISPANIC vs. BLACK NON HISP
  * WHITE NON HISPANIC vs. WHITE NON HISP
* Case structure of the names changed beginning of 2013 from "UPPERCASE" to "Name"
* Many duplicated rows were spotted

```{r babynames_data}

# Cleaning up the baby_names dataset
baby_names_data <-
  read_csv("./data/baby_names/Popular_Baby_Names.csv") %>% 
  janitor::clean_names() %>%                                    # Changes column names to lowercase
  distinct(year_of_birth,                                       # Parses df to remove any "duplicates" that
           gender,                                              # in the listed variables 
           ethnicity, 
           childs_first_name, 
           count, 
           rank, 
           .keep_all = TRUE) %>%                                # Makes sure unlisted columns are included
  mutate(childs_first_name = str_to_lower(childs_first_name),   # Changes specified columns to all lowercase
         ethnicity = str_to_lower(ethnicity),
         gender = str_to_lower(gender), 
         ethnicity = str_replace(ethnicity,                     # Replaces the short-hand with complete description
                            "asian and paci(?!fic islander)",   # (?!characters) = not followed by "characters"
                            "asian and pacific islander"),      
         ethnicity = str_replace(ethnicity,
                            "black non hisp(?!anic)",
                            "black non hispanic"),
         ethnicity = str_replace(ethnicity,
                            "white non hisp(?!anic)",
                            "white non hispanic"))
                                  
```

While cleaning up, a peculiarity in the # of observations was noticed. When `distinct()` did not include `count` and `rank`, `baby_names_data` has 12180 observations. However, when `distinct()` includes `count` and `rank`, it turns into 12181 observations. Using `janitor::get_dupes()`, we get: 

```{r dupes, echo = FALSE} 

janitor::get_dupes(baby_names_data, year_of_birth, gender, ethnicity, childs_first_name)

```

This difference was apparently due to the different case structure between "Mc __K__ enzie" vs "Mc __k__ enzie". Since these were discnerably considered different in the original data, I decided to keep these as "separate names" despite the same output due to applying `str_to_lower()` to the name variables. Other variations in "mckenzie" case structure were considered duplicates. 

## Obtaining useful information from cleaned baby dataset
Now that the dataset is cleaned and tidied, we can pull 3 data subsets of interest and make a table out of it: 

#### Changes in Ranking for the female name "Olivia" Over Time by Ethnicity
Since the variables and column names were in lowercase, we need to modify them first. After that, we need to change it to wide form and print the table using `kable()`. 

```{r olivia_rank, results = 'asis'}

# Making tibble for the ranking of "Olivia" over the years separated by ethnicity. Prints it out using kable()
baby_names_data %>% 
  filter(childs_first_name == "olivia",                                  # Filters the data by name & gender
         gender == "female") %>% 
  select(-gender, -childs_first_name, -count) %>%                        # Removes unneeded variables
  mutate(ethnicity = str_to_title(ethnicity)) %>%                        # Capitalize ethnicity variables for table
  rename(Ethnicity = ethnicity) %>%                                      # Capitalize "Ethnicity" for table
  pivot_wider(names_from = year_of_birth,                                # Convert to wide form; columns = year,
              values_from = rank) %>%                                    # rows =  ethnicity
  select(Ethnicity, "2011", "2012", "2013", "2014", "2015", "2016") %>%  # Arrange in increasing year
  kable(format = "markdown")                                             # Prints a pretty table in markdown

```

The resulting table above separate the "Olivia"s by ethnicity. This way, we can see how its ranking fluctuates from 2011-2016 within each ethnicities.

#### Names for the male's 1st rank each year by ethnicity
Similarly, we do the same general process as above to find the 1st ranked name for males. 

```{r rank1_male_names, results = 'asis'}

baby_names_data %>% 
  filter(rank == 1,                                                      # Filters by rank "1" and gender
         gender == "male") %>% 
  select(-gender, -rank, -count) %>%                                     # Removes unneeded variables
  mutate(ethnicity = str_to_title(ethnicity),                            # Capitalize ethnicity & names for table
         childs_first_name = str_to_title(childs_first_name)) %>% 
  rename(Ethnicity = ethnicity) %>%                                      # Capitalize "Ethnicity" for table 
  pivot_wider(names_from = year_of_birth,                                # Convert to wide form; column = year,
              values_from = childs_first_name) %>%                       # rows = ethnicity
  select(Ethnicity, "2011", "2012", "2013", "2014", "2015", "2016") %>%  # Arrange to increasing year
  kable(format = "markdown")                                             # Prints a pretty table in markdown

```

The resulting table above now shows how the 1st-ranked name changes between 2011-2016. It is also separated by ethnicity.

#### Graph of the counts from each rank of white non-hispanic males' top 100 born in 2016
Finally, we produce a scatterplot that shows the difference in counted numbers between each of the top 100 white non-hispanic male names. 

```{r scatterplot_top100_whitemale, fig.width = 10}
baby_names_data %>% 
  filter(year_of_birth == 2016,                                   # Filter by the criteria
         gender == "male", 
         ethnicity == "white non hispanic") %>%
  ggplot(aes(x = rank, y = count)) +                              # Assigns x and y variable for the plot
  theme_minimal() +
  geom_point(alpha = 0.2, colour = "blue4") +                     # Added an alpha to make overlaps visible, if any
  labs(title = "Top 100 Real Name Counts",                        # Specifies title, subtitles, x, y -axes
       subtitle = "for White, non-Hispanic Males Born in 2016",
       x = "Ranking from 1-100",
       y = "Real Counts") +
  theme(plot.title = element_text(hjust = 0.5, size = 18),        # Adjusted sizing and alignment of title/subtitle
        plot.subtitle = element_text(hjust = 0.5, size = 8))

```

In making this plot, adding color identifiers were considered but was not used as there were too many variables, which caused color duplicates. Since the names should be unique, there must not be duplicates. A single color was chosen instead to provide some contrast as well as `alpha =` to somewhat discern stacked datapoints.
